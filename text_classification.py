# -*- coding: utf-8 -*-
"""Text_Classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Mwhn6ehSZmOaRBW2k1mLgSbFy88kd9XA
"""

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/MyDrive/Colab/2.1.Text_Classification

# Commented out IPython magic to ensure Python compatibility.
# %pwd

"""# 1. Tải bộ dữ liệu:"""

# https://drive.google.com/file/d/1N7rk-kfnDFIGMeX0ROVTjKh71gcgx-7R/view?usp=sharing
!gdown --id 1N7rk-kfnDFIGMeX0ROVTjKh71gcgx-7R

"""# 2. Import các thư viện cần thiết"""

import string  # Cung cấp các hàm cơ bản để thao tác với chuỗi ký tự.

import nltk  # (Natural Language Toolkit):thư viện xử lý ngôn ngữ tự nhiên
nltk.download('stopwords')
nltk.download('punkt')

import pandas as pd # Cung cấp các cấu trúc dữ liệu hiệu quả và các công cụ để làm việc với dữ liệu
import numpy as np  # Cung cấp các đối tượng mảng đa chiều và các hàm toán học để làm việc với các mảng này
import matplotlib.pyplot as plt #

# Thư viện ML phổ biến, giúp xây dựng và triển khai các mô hình ML phức tạp một cách nhanh chóng.
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import LabelEncoder

"""# 3. Đọc dữ liệu"""

DATASET_PATH = '/content/drive/MyDrive/Colab/2.1.Text_Classification/2cls_spam_text_cls.csv'
df = pd.read_csv(DATASET_PATH)

messages = df['Message'].values.tolist()
labels = df['Category'].values.tolist()

# review dataset
df

"""# 4. Tiền xử lý dữ liệu

## Xử lý dữ liệu đặc trưng
"""

# chuyển tất cả chuỗi sang chữ thường
def lowercase(text):
    return text.lower()

# xóa dấu câu
def punctuation_removal(text):
    translator = str.maketrans('', '', string.punctuation)
    return text.translate(translator)

# tách từ
def tokenize(text):
    return nltk.word_tokenize(text)

# xóa stopwords
def remove_stopwords(tokens):
    stop_words = nltk.corpus.stopwords.words('english')
    return [token for token in tokens if token not in stop_words]

# đưa từ về dạng gốc
def stemming(tokens):
    stemmer = nltk.PorterStemmer()
    return [stemmer.stem(token) for token in tokens]

# tiền xử lý văn bản (tổng hợp)
def preprocess_text(text):
    text = lowercase(text)
    text = punctuation_removal(text)
    tokens = tokenize(text)
    tokens = remove_stopwords(tokens)
    tokens = stemming(tokens)
    return tokens

# tạo một bộ từ điển (Dictionary), chứa tất các từ hoặc ký tự xuất hiện trong toàn bộ Messages sau khi tiền xử lý.
def create_dictionary(messages):
    dictionary = []
    for tokens in messages:
        for token in tokens:
            if token not in dictionary:
                dictionary.append(token)
    return dictionary

# đếm tần xuất các từ trong bộ từ điển xuất hiện trong toàn bộ messages (vector đặc trưng cho các message)
def create_features(tokens, dictionary):
    features = np.zeros(len(dictionary))
    for token in tokens:
        if token in dictionary:
            features[dictionary.index(token)] += 1
    return features

# tiền xử lý toàn bộ nội dung message(trong dataset)
messages = [preprocess_text(message) for message in messages]

# tạo bộ từ điển từ messages
dictionary = create_dictionary(messages)

# tạo vector đặc trưng cho các message
X = np.array([create_features(tokens, dictionary) for tokens in messages])

"""## Xử lý dữ liệu nhãn"""

le = LabelEncoder()
y = le.fit_transform(labels)
print(f'Classes: {le.classes_}')
print(f'Encoded labels: {y}')

"""# 5. Chia bộ dữ liệu train/val/test"""

VAL_SIZE = 0.2 # 20% của bộ dữ liệu gốc ~ 20%
TEST_SIZE = 0.125 # 12.5% của 80%(phần còn lại của bộ dữ liệu gốc) ~ 10%
# phần còn lại thuộc về TRAIN_SIZE ~ 70% của bộ dữ liệu gốc
SEED = 0

X_train, X_val, y_train, y_val = train_test_split(X, y,
                                                  test_size=VAL_SIZE,
                                                  shuffle=True,
                                                  random_state=SEED)
X_train, X_test, y_train, y_test = train_test_split(X_train, y_train,
                                                    test_size=TEST_SIZE,
                                                    shuffle=True,
                                                    random_state=SEED)

"""# 6. Huấn luyện mô hình:"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# model = GaussianNB()
# 
# print('Start training...')
# model = model.fit(X_train, y_train)
# print('Training completed!')

"""# 7. Đánh giá mô hình"""

# đánh giá lại model đã train ở Step6
y_val_pred = model.predict(X_val)
y_test_pred = model.predict(X_test)

val_accuracy = accuracy_score(y_val, y_val_pred)
test_accuracy = accuracy_score(y_test, y_test_pred)

print(f'Val accuracy: {val_accuracy}')
print(f'Test accuracy: {test_accuracy}')

"""# 8. Thực hiện dự đoán"""

# dùng model đã train ở step6 dự đoán 1 message được truyền vào
def predict(text, model, dictionary):
    processed_text = preprocess_text(text)
    features = create_features(text, dictionary)
    features = np.array(features).reshape(1, -1)
    prediction = model.predict(features)
    prediction_cls = le.inverse_transform(prediction)[0]

    return prediction_cls

# thử nghiệm dự đoán
test_input = 'I am actually thinking a way of doing something useful'
prediction_cls = predict(test_input, model, dictionary)
print(f'Prediction: {prediction_cls}')













